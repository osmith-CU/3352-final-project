{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8ddb15-c550-4399-91a5-fe13d4caa321",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# CSCI 3352, Spring 2022\n",
    "# FINAL PROJECT\n",
    "\n",
    "<br> \n",
    "\n",
    "### Owen Smith, Kyle Ma\n",
    "\n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc48e2cb-31cc-45e7-84ee-dc5aad04b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import tree\n",
    "from pyvis.network import Network\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b756ecc1-17d2-40d0-9063-2ca65c48c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ITERATE THROUGH NETWORKS DIRECTORY, HANDLE FILES ###\n",
    "directory = 'networks'\n",
    "for filename in os.scandir(directory):\n",
    "    filename = filename.name\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    ext = str(ext)[0:4]\n",
    "    if ext == '.csv' and filename != 'references.csv':\n",
    "        data = np.loadtxt(open(directory + '/' + filename, \"rb\"), delimiter=\",\", skiprows=1)\n",
    "        edgelist = ''\n",
    "        listfile = open(directory + '/' + filename[:-4] + '.txt', 'w')\n",
    "        for row in range(0, len(data)):\n",
    "            for col in range(0, len(data[row])):\n",
    "                if data[row][col] != 0:\n",
    "                    edgelist = edgelist + str(col) + ' ' + str(row) + '\\n'\n",
    "        d = listfile.write(edgelist)\n",
    "        listfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b538fb-963f-4fdd-b7a6-2cb3cc4dee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a graph G and returns a list of network statistics\n",
    "def gather_network_stats(G):\n",
    "    def compute_MGD(G):\n",
    "        path = list((dict(nx.all_pairs_shortest_path_length(G)).values())) #takes return and converts to list of dicts\n",
    "        Z = 0\n",
    "        l_sum = 0\n",
    "\n",
    "        for node in path:\n",
    "            tmp = list(node.values()) #convert node dict to list of values\n",
    "            tmp.remove(0) #remove all instances of 0\n",
    "            Z = Z + len(tmp) #calculate Z from size of list\n",
    "            l_sum = l_sum + sum(tmp) #add all the path lengths to the total for the numerator later on\n",
    "\n",
    "        MGD = l_sum / Z\n",
    "        return MGD\n",
    "    \n",
    "    def percent_single_degree(G): #gets percentage of nodes with degree of one, as these edge suggest specialized predation\n",
    "        degrees = dict(G.degree())\n",
    "        degrees = list(degrees.values())\n",
    "        single_degree_count = 0\n",
    "        for k in degrees:\n",
    "            if k == 1:\n",
    "                single_degree_count += 1\n",
    "        return single_degree_count / G.number_of_nodes()\n",
    "\n",
    "    def count_FFBL_motifs(G,flag):\n",
    "        FFL_count = 0\n",
    "        FBL_count = 0\n",
    "\n",
    "        ### MY CODE ###\n",
    "        FFL_pairs = [] #lists that will contain pairs for later printing if flag == 1\n",
    "        FBL_pairs = []\n",
    "\n",
    "        for i in G.nodes(): #loop for suggested enumeration\n",
    "            for j in G.neighbors(i): #paths of length 1\n",
    "                for k in G.neighbors(j): #paths of length 2\n",
    "                    if (i != k): #eliminate bidirectionals\n",
    "                        if (G.has_edge(i, k)): #if there is an edge from i -> k, it is a FFL\n",
    "                            FFL_count += 1\n",
    "                            FFL_pairs.append(((i,j), (j,k), (i,k)))\n",
    "                        if (G.has_edge(k, i)): #if there is an edge from k -> i, it is a FBL\n",
    "                            FBL_count += 1\n",
    "                            FBL_pairs.append(((i,j), (j,k), (k,i)))\n",
    "\n",
    "        FBL_count = int(FBL_count / 3) #divide FBL_count by 3 to retroactively account for duplicates\n",
    "\n",
    "        if (flag == 1): #print flag\n",
    "            for i in FFL_pairs:\n",
    "                print(\"FFL: \", i)\n",
    "            FBL_pairs = FBL_pairs[::3] #takes every third element to get rid of duplicates (kinda jank but it works)\n",
    "            for i in FBL_pairs:\n",
    "                print(\"FBL:\", i)\n",
    "\n",
    "        return (FFL_count,FBL_count)\n",
    "    \n",
    "    n = G.number_of_nodes() #builtin function that returns number of nodes as an int\n",
    "    m = G.number_of_edges() #builtin funciton that reutnrs number of edges as an int\n",
    "    \n",
    "    degrees = dict(G.degree())\n",
    "    totalDegrees = sum(degrees.values()) #get values, sum, divide by number of nodes\n",
    "    kmean =  totalDegrees / n #calculate mean\n",
    "    \n",
    "    degree_lst = list(degrees.values())\n",
    "    kmax = max(degree_lst)\n",
    "    \n",
    "    C = nx.transitivity(G)\n",
    "    node_connectivity = nx.node_connectivity(G)\n",
    "    MGD = compute_MGD(G)\n",
    "    FFL_count, FBL_count = count_FFBL_motifs(G, 0)\n",
    "    FFL_count = FFL_count / n\n",
    "    FBL_count = FBL_count / n\n",
    "    specialized_nodes = percent_single_degree(G)\n",
    "    \n",
    "    percent_cannibal = 0\n",
    "    for node in G.nodes():\n",
    "        if node in G.neighbors(node):\n",
    "            percent_cannibal += 1\n",
    "    percent_cannibal = percent_cannibal / n\n",
    "    return [n, m, kmean, kmax, C, node_connectivity, MGD, FFL_count, FBL_count, specialized_nodes, percent_cannibal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b3660d-60b7-40df-8168-74583437e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp(filename):\n",
    "    # returns temperature as a float\n",
    "    df = pd.read_csv(\"our_references.csv\")\n",
    "    temp = df[[\"Filename\", \"Temperature\"]]\n",
    "    temperature = temp.loc[temp[\"Filename\"] == filename,\"Temperature\"].iloc[0]\n",
    "    return float(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98b3076c-324b-4b37-9d93-33d67f2470fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_coefficients(data_array):\n",
    "    # returns correlation coefficients as a list\n",
    "    df = pd.DataFrame(data_array, columns = ['network', \"nodes\", \"degrees\", 'average degrees', 'highest degree', 'Cluster Coeff', 'connectivity', 'MGD', \n",
    "                                             'FFL', 'FBL', 'special nodes', 'percent_cannibal', 'Temperature'])\n",
    "    correlations = df.corr()['Temperature'][:-1]\n",
    "    print(df)\n",
    "    return correlations #this line for returning as dataframe\n",
    "    #return correlations.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5137335a-eff1-45ac-a0f4-b0e84beee152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes :  26\n",
      "number of edges :  125\n",
      "average degrees :  9.615384615384615\n",
      "highest degree :  20\n",
      "Cluster Coeff :  0.3758503401360544\n",
      "connectivity :  0\n",
      "MGD :  2.401666666666667\n",
      "FFL :  9.923076923076923\n",
      "FBL :  2.0384615384615383\n",
      "special nodes :  0.0\n",
      "percent_cannibal :  0.11538461538461539\n"
     ]
    }
   ],
   "source": [
    "# iterates through networks directory and reads each in as networkx graph G\n",
    "directory = 'networks'\n",
    "data = []\n",
    "show = True\n",
    "for filename in os.scandir(directory):\n",
    "    filename = filename.name\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    ext = str(ext)[0:4]\n",
    "    if ext == '.txt' and filename != 'README':\n",
    "        G = nx.read_edgelist(directory + '/' + filename, create_using=nx.DiGraph)\n",
    "        network_stats = [filename]\n",
    "        network_stats = network_stats + gather_network_stats(G)\n",
    "        network_stats.append(get_temp(filename[:-4]))\n",
    "        data.append(network_stats)\n",
    "        if filename == \"FW_003.txt\":\n",
    "            species = pd.read_csv(\"species/\"+ filename[:-4] + \".csv\").columns[1:]\n",
    "            mapping = {}\n",
    "            for i, a in enumerate(G.nodes()):\n",
    "                mapping[a] = species[int(a)]\n",
    "#                 print(len(G.nodes()))\n",
    "#                 print(len(species))\n",
    "                a = species[int(a)]\n",
    "                #print(a)\n",
    "            H = nx.relabel_nodes(G, mapping)\n",
    "            stats = gather_network_stats(G)\n",
    "            #nx.draw(H, with_labels = True)\n",
    "            net = Network(notebook = True)\n",
    "            net = Network('2000px', '2000px', directed = True)\n",
    "            net.from_nx(H)\n",
    "            for edge in net.edges:\n",
    "                edge['label'] = ''\n",
    "            net.show(\"test.html\")\n",
    "            show = False\n",
    "    # nx.draw(G)\n",
    "    # plt.show()\n",
    "#[n, m, kmean, kmax, C, node_connectivity, MGD, FFL_count, FBL_count, specialized_nodes, percent_cannibal]\n",
    "labels = [\"nodes\", \"number of edges\", 'average degrees', 'highest degree', 'Cluster Coeff', 'connectivity', 'MGD', \n",
    "                                             'FFL', 'FBL', 'special nodes', 'percent_cannibal']\n",
    "for i, a in enumerate(stats):\n",
    "    print(labels[i], ': ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c30d1bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in net.edges:\n",
    "    i['label'] = ''\n",
    "    print(i['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6479331-5f5f-4c12-a134-552e8af25d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          network  nodes  degrees  average degrees  highest degree  \\\n",
      "0      FW_001.txt     39      183         9.384615              26   \n",
      "1      FW_002.txt     11       36         6.545455              11   \n",
      "2      FW_003.txt     26      125         9.615385              20   \n",
      "3      FW_004.txt     32      137         8.562500              19   \n",
      "4      FW_005.txt     43      409        19.023256              54   \n",
      "5      FW_006.txt     30      225        15.000000              32   \n",
      "6      FW_007.txt     42      219        10.428571              20   \n",
      "7      FW_008.txt    247     3301        26.728745             199   \n",
      "8      FW_009.txt     37      237        12.810811              34   \n",
      "9      FW_010.txt     35      247        14.114286              42   \n",
      "10     FW_011.txt     71      338         9.521127              50   \n",
      "11  FW_012_01.txt     37      120         6.486486              26   \n",
      "12  FW_012_02.txt     44      145         6.590909              32   \n",
      "13  FW_013_01.txt     45      186         8.266667              39   \n",
      "14  FW_013_02.txt     45      232        10.311111              36   \n",
      "15  FW_013_03.txt     53      210         7.924528              35   \n",
      "16  FW_013_04.txt     53      249         9.396226              34   \n",
      "17  FW_013_05.txt     81      617        15.234568              54   \n",
      "18  FW_014_01.txt     70      361        10.314286              46   \n",
      "19  FW_014_02.txt     71      541        15.239437              43   \n",
      "20  FW_014_03.txt     77      689        17.896104              52   \n",
      "21  FW_014_04.txt     91      820        18.021978              63   \n",
      "22  FW_015_01.txt     75      617        16.453333              53   \n",
      "23  FW_015_02.txt     65      399        12.276923              43   \n",
      "24  FW_015_03.txt     75      520        13.866667              54   \n",
      "25  FW_015_04.txt     93      944        20.301075              61   \n",
      "26  FW_016_01.txt     36      238        13.222222              43   \n",
      "27  FW_017_01.txt    193      809         8.383420             117   \n",
      "28  FW_017_02.txt    144      510         7.083333              87   \n",
      "29  FW_017_03.txt    143      875        12.237762             117   \n",
      "30  FW_017_04.txt     98      491        10.020408              76   \n",
      "31  FW_017_05.txt    166      569         6.855422             118   \n",
      "32  FW_017_06.txt    122      747        12.245902              99   \n",
      "\n",
      "    Cluster Coeff  connectivity       MGD        FFL       FBL  special nodes  \\\n",
      "0        0.203390             0  2.705409   6.564103  0.923077       0.051282   \n",
      "1        0.232143             1  1.844444   3.909091  0.454545       0.000000   \n",
      "2        0.375850             0  2.401667   9.923077  2.038462       0.000000   \n",
      "3        0.189474             0  2.008043   6.750000  0.312500       0.031250   \n",
      "4        0.376996             0  1.929966  52.790698  9.162791       0.023256   \n",
      "5        0.264470             0  1.935013  23.733333  3.333333       0.000000   \n",
      "6        0.188207             0  3.185234   7.523810  0.666667       0.000000   \n",
      "7        0.048634             1  3.980612  43.356275  0.813765       0.000000   \n",
      "8        0.267635             1  2.395062  16.891892  1.729730       0.000000   \n",
      "9        0.191457             1  2.045378  15.942857  3.857143       0.000000   \n",
      "10       0.123003             0  3.375483   5.366197  0.154930       0.042254   \n",
      "11       0.180077             0  3.372881   3.027027  0.108108       0.108108   \n",
      "12       0.172372             0  2.278729   3.681818  0.022727       0.136364   \n",
      "13       0.271259             0  2.406965   9.600000  1.266667       0.044444   \n",
      "14       0.267785             0  2.493649  12.511111  0.622222       0.044444   \n",
      "15       0.136437             0  4.064000   3.452830  0.301887       0.000000   \n",
      "16       0.142943             0  4.343082   5.000000  0.150943       0.018868   \n",
      "17       0.223567             0  2.205383  37.679012  3.333333       0.172840   \n",
      "18       0.135076             0  3.048270  10.742857  0.485714       0.100000   \n",
      "19       0.237215             0  2.541756  34.014085  2.422535       0.126761   \n",
      "20       0.222652             0  2.229043  38.909091  2.948052       0.051948   \n",
      "21       0.233127             0  2.174585  48.703297  2.923077       0.164835   \n",
      "22       0.230406             0  2.294841  33.933333  2.946667       0.106667   \n",
      "23       0.242243             0  2.371957  24.969231  2.707692       0.061538   \n",
      "24       0.210976             0  2.378005  23.320000  2.160000       0.120000   \n",
      "25       0.273007             0  2.249735  64.387097  5.602151       0.064516   \n",
      "26       0.213408             1  2.157945  28.027778  3.833333       0.000000   \n",
      "27       0.227761             0  2.441819   6.295337  0.041451       0.113990   \n",
      "28       0.268612             0  2.057740   4.708333  0.055556       0.145833   \n",
      "29       0.412376             0  2.039410  20.741259  0.559441       0.062937   \n",
      "30       0.235503             0  1.937796   8.642857  0.265306       0.030612   \n",
      "31       0.113876             0  1.544304   2.722892  0.000000       0.216867   \n",
      "32       0.406857             0  2.012476  21.401639  0.442623       0.040984   \n",
      "\n",
      "    percent_cannibal  Temperature  \n",
      "0           0.102564         64.4  \n",
      "1           0.181818         73.5  \n",
      "2           0.115385         78.0  \n",
      "3           0.156250         74.9  \n",
      "4           0.209302         64.4  \n",
      "5           0.200000         68.4  \n",
      "6           0.190476         70.2  \n",
      "7           0.040486         81.0  \n",
      "8           0.135135         69.8  \n",
      "9           0.057143         69.8  \n",
      "10          0.070423         40.9  \n",
      "11          0.027027         62.7  \n",
      "12          0.068182         62.7  \n",
      "13          0.111111         50.0  \n",
      "14          0.200000         50.0  \n",
      "15          0.018868         50.0  \n",
      "16          0.018868         50.0  \n",
      "17          0.098765         50.0  \n",
      "18          0.071429         48.2  \n",
      "19          0.112676         48.2  \n",
      "20          0.077922         48.2  \n",
      "21          0.109890         48.2  \n",
      "22          0.093333         49.6  \n",
      "23          0.153846         49.6  \n",
      "24          0.093333         49.6  \n",
      "25          0.150538         49.6  \n",
      "26          0.222222         55.0  \n",
      "27          0.020725         80.3  \n",
      "28          0.013889         82.2  \n",
      "29          0.041958         76.8  \n",
      "30          0.030612         78.0  \n",
      "31          0.012048         74.0  \n",
      "32          0.081967         73.2  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nodes               0.357052\n",
       "degrees             0.209314\n",
       "average degrees    -0.159898\n",
       "highest degree      0.391070\n",
       "Cluster Coeff       0.212016\n",
       "connectivity        0.267024\n",
       "MGD                -0.277938\n",
       "FFL                -0.297519\n",
       "FBL                -0.254127\n",
       "special nodes      -0.169698\n",
       "percent_cannibal   -0.171546\n",
       "Name: Temperature, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_correlation_coefficients(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae83ab9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['radius', 'eccentricity'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14220/3741919652.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m df = pd.DataFrame(data, columns = ['network', \"nodes\", \"degrees\", 'average degrees', 'highest degree', 'Cluster Coeff', 'connectivity', 'MGD',\n\u001b[0;32m      2\u001b[0m                                    'FFL', 'FBL', 'special nodes', 'percent_cannibal', 'Temperature'])\n\u001b[1;32m----> 3\u001b[1;33m X = df[[\"nodes\", \"degrees\", 'average degrees', 'highest degree', 'Cluster Coeff', 'connectivity', \n\u001b[0m\u001b[0;32m      4\u001b[0m         'MGD', 'FFL', 'FBL', 'special nodes', 'percent_cannibal', 'radius', 'eccentricity',]]\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Temperature'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['radius', 'eccentricity'] not in index\""
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns = ['network', \"nodes\", \"degrees\", 'average degrees', 'highest degree', 'Cluster Coeff', 'connectivity', 'MGD',\n",
    "                                   'FFL', 'FBL', 'special nodes', 'percent_cannibal', 'Temperature'])\n",
    "X = df[[\"nodes\", \"degrees\", 'average degrees', 'highest degree', 'Cluster Coeff', 'connectivity', \n",
    "        'MGD', 'FFL', 'FBL', 'special nodes', 'percent_cannibal', 'radius', 'eccentricity',]]\n",
    "y = df['Temperature']\n",
    "\n",
    "num_trials = 10000\n",
    "rand_set = list(range(0, 33))\n",
    "rand_set_track = list(range(0, 33))\n",
    "average_errors = []\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "empirical_net = {}\n",
    "for trial in range(0, num_trials):\n",
    "    # create lists and generate random indeces for training from global dataset\n",
    "    errors = []\n",
    "    empirical_set = []\n",
    "    training_set = []\n",
    "    empirical_set_temps = []\n",
    "    training_set_temps = []\n",
    "    training_set_indeces = np.random.choice(rand_set, size = 30, replace=False)\n",
    "    rand_set_track = [val for val in rand_set if val not in training_set_indeces]\n",
    "    #print(rand_set_track)\n",
    "    # append generated values to respective sets\n",
    "    for index in training_set_indeces:\n",
    "        training_set.append(X[index])\n",
    "        training_set_temps.append(y[index])\n",
    "    for index in rand_set_track:\n",
    "        empirical_set.append(X[index])\n",
    "        empirical_set_temps.append(y[index])\n",
    "    # machine learning regression tree\n",
    "    ML = tree.DecisionTreeRegressor()\n",
    "    ML.fit(training_set, training_set_temps)\n",
    "    for index in range(0, len(empirical_set_temps)):\n",
    "        prediction = ML.predict([empirical_set[index]])\n",
    "        errors.append(abs(empirical_set_temps[index] - prediction))\n",
    "        if rand_set_track[index] in empirical_net:\n",
    "            #print(\"Here\")\n",
    "            empirical_net[rand_set_track[index]].append((empirical_set_temps[index] - prediction)[0])\n",
    "            #print(empirical_net)\n",
    "        else:\n",
    "            #print(\"here\")\n",
    "            empirical_net[rand_set_track[index]] = (empirical_set_temps[index] - prediction).tolist()\n",
    "            #print(empirical_net)\n",
    "    average_errors.append(np.mean(errors))\n",
    "for i in empirical_net:\n",
    "    empirical_net[i] = np.mean(empirical_net[i])\n",
    "empirical_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0cb45b-d236-4b6a-a7bf-c0e209ee3318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
